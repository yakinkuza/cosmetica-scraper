import os
import json
import time
import requests

import gspread
from gspread.exceptions import WorksheetNotFound

# -----------------------------
# Config
# -----------------------------
URL = "https://cosmetica.fda.moph.go.th/CMT_SEARCH_BACK_NEW/Home/FUNCTION_CENTER"

# ID ‡∏Ç‡∏≠‡∏á Google Sheet (‡∏ï‡∏±‡∏ß‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏µ‡πà‡∏Ñ‡∏∏‡∏ì‡∏ö‡∏µ‡∏°‡πÉ‡∏´‡πâ‡∏°‡∏≤)
SHEET_ID = os.getenv(
    "SHEET_ID",
    "1sEwh39a_C_jcYXBPbkU6tN_nWUmp7_juEQkBy7gcoxM",
)

# ‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏ó‡πá‡∏ö‡πÉ‡∏ô Google Sheet
LIST_SHEET_NAME = os.getenv("LIST_SHEET_NAME", "LIST")
RESULT_SHEET_NAME = os.getenv("RESULT_SHEET_NAME", "RESULT")
ERROR_SHEET_NAME = os.getenv("ERROR_SHEET_NAME", "ERROR")

# ‡∏à‡∏≥‡∏ô‡∏ß‡∏ô record ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô 1 ‡∏Ñ‡∏£‡∏±‡πâ‡∏á (‡∏Å‡∏±‡∏ô‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ run ‡∏ô‡∏≤‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ)
MAX_PER_RUN = int(os.getenv("MAX_PER_RUN", "500"))

# batch ‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤ Google Sheet ‡∏ó‡∏µ‡∏•‡∏∞‡∏Å‡∏µ‡πà‡πÅ‡∏ñ‡∏ß
BATCH_WRITE_SIZE = int(os.getenv("BATCH_WRITE_SIZE", "50"))

# -----------------------------
# Helper: connect gspread
# -----------------------------
def get_gspread_client():
    """
    ‡πÉ‡∏ä‡πâ GOOGLE_SERVICE_ACCOUNT_JSON ‡∏à‡∏≤‡∏Å GitHub Secret
    ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á gspread client
    """
    creds_json = os.environ["GOOGLE_SERVICE_ACCOUNT_JSON"]
    creds_dict = json.loads(creds_json)
    return gspread.service_account_from_dict(creds_dict)


# -----------------------------
# FDA API
# -----------------------------
def build_payload(regnos: str) -> dict:
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á payload ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏Å get_detail_regnos
    regnos ‡∏ï‡πâ‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏Ç‡πÅ‡∏ö‡∏ö‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡∏µ‡∏î ‡πÄ‡∏ä‡πà‡∏ô "1026700038284"
    """
    return {
        "MODEL": {
            "M_SYSTEM_SETTING": {"FUNCTION_NAME": "get_detail_regnos"},
            "M_AUTHENTICATION": {},
            "DATA_SET": {},
            "DATA_TRANSLATION_OB": None,
            "Search": {},
            "datail_string": {
                "regnos": regnos,  # ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏™‡∏∏‡∏î
                # field ‡∏≠‡∏∑‡πà‡∏ô‡∏õ‡∏•‡πà‡∏≠‡∏¢‡∏ß‡πà‡∏≤‡∏á ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡πÄ‡∏ï‡∏¥‡∏°‡πÉ‡∏´‡πâ‡πÄ‡∏≠‡∏á
            },
            "M_tran": {},
        }
    }


def call_fda(regnos: str, retry: int = 3, sleep_sec: float = 1.0) -> dict | None:
    """
    ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API FDA ‡∏î‡πâ‡∏ß‡∏¢ regnos (‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡∏µ‡∏î) ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ datail_string (dict)
    ‡∏ñ‡πâ‡∏≤ error ‡∏´‡∏•‡∏≤‡∏¢‡∏Ñ‡∏£‡∏±‡πâ‡∏á ‡∏Ñ‡∏∑‡∏ô None
    """
    payload = build_payload(regnos)
    headers = {
        "Content-Type": "application/json",
        "Accept": "application/json, text/plain, */*",
    }

    for attempt in range(1, retry + 1):
        try:
            r = requests.post(URL, headers=headers, data=json.dumps(payload), timeout=30)
            r.raise_for_status()
            data = r.json()

            model = data.get("MODEL", data)
            detail = model.get("datail_string", None)

            # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏î‡πâ detail ‡∏Å‡∏•‡∏±‡∏ö‡∏°‡∏≤ ‡∏Å‡πá‡∏à‡∏ö
            if detail:
                return detail

            # ‡∏ñ‡πâ‡∏≤ detail ‡∏ß‡πà‡∏≤‡∏á ‡∏•‡∏≠‡∏á print ‡∏î‡∏π‡πÄ‡∏û‡∏∑‡πà‡∏≠ debug
            print(f"  ‚ö† regnos {regnos}: datail_string is empty")
            return None

        except Exception as e:
            print(f"  ‚ùå regnos {regnos}: attempt {attempt} failed -> {e}")
            if attempt < retry:
                time.sleep(sleep_sec * attempt)
            else:
                return None


# -----------------------------
# Helper: flatten detail ‚Üí row
# -----------------------------
DETAIL_KEYS = [
    "regnos",
    "type",
    "lb_lct_type",
    "EMPLOYER",
    "lb_NAME_EMPLOYER",
    "status_lct",
    "lb_format_regnos",
    "lb_trade_Tpop",
    "lb_trade_Tpop2",
    "lb_cosnm_Tpop",
    "lb_cosnm_Tpop2",
    "lb_appdate",
    "lb_fileattach_count",
    "lb_status",
    "lb_expdate",
    "lb_no_regnos",
    "lb_mode",
    "lb_applicability_name",
    "lb_condition",
    "lb_application_name",
    "lb_usernm_pop",
    "lb_locat_pop",
    "lb_fac_pop",
    "lb_NO_pop",
    "count_eng",
    "data_ampole",
    "file",
    "fileType",
    "province",
    "identify",
    "lctnmno",
    "physical_detail",
]


def normalize_value(v):
    if v is None:
        return ""
    if isinstance(v, (dict, list)):
        return json.dumps(v, ensure_ascii=False)
    return str(v)


def detail_to_row(notify_number: str, detail: dict) -> list:
    """
    ‡πÅ‡∏õ‡∏•‡∏á dict datail_string ‚Üí list ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡∏•‡∏á Google Sheet
    column ‡πÅ‡∏£‡∏Å‡∏Ñ‡∏∑‡∏≠ notify_number ‡πÅ‡∏ö‡∏ö‡∏°‡∏µ‡∏Ç‡∏µ‡∏î
    """
    row = [notify_number]
    for key in DETAIL_KEYS:
        row.append(normalize_value(detail.get(key)))
    return row


def get_result_header() -> list:
    return ["notify_number"] + DETAIL_KEYS


# -----------------------------
# Main
# -----------------------------
def main():
    print("üöÄ Start scraping")

    gc = get_gspread_client()
    sh = gc.open_by_key(SHEET_ID)

    # --- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° worksheet ‡∏ï‡πà‡∏≤‡∏á ‡πÜ ---
    ws_list = sh.worksheet(LIST_SHEET_NAME)

    try:
        ws_result = sh.worksheet(RESULT_SHEET_NAME)
    except WorksheetNotFound:
        ws_result = sh.add_worksheet(RESULT_SHEET_NAME, rows=1000, cols=50)
        ws_result.append_row(get_result_header())
        print(f"‚úÖ Created sheet '{RESULT_SHEET_NAME}' with header")

    try:
        ws_error = sh.worksheet(ERROR_SHEET_NAME)
    except WorksheetNotFound:
        ws_error = sh.add_worksheet(ERROR_SHEET_NAME, rows=1000, cols=10)
        ws_error.append_row(["notify_number", "regnos_no_dash", "error_message"])
        print(f"‚úÖ Created sheet '{ERROR_SHEET_NAME}' with header")

    # --- ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏•‡∏Ç‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å LIST ---
    all_vals = ws_list.col_values(1)  # ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå A ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    if not all_vals:
        print("‚ùå LIST sheet col A ‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤")
        return

    # ‡πÅ‡∏¢‡∏Å header + list ‡∏à‡∏£‡∏¥‡∏á
    if all_vals[0].strip().lower().startswith("notify"):
        notify_all = [v.strip() for v in all_vals[1:] if v.strip()]
    else:
        notify_all = [v.strip() for v in all_vals if v.strip()]

    print(f"üî¢ Total notify numbers in LIST: {len(notify_all)}")

    # --- ‡πÇ‡∏´‡∏•‡∏î notify ‡∏ó‡∏µ‡πà‡πÄ‡∏Ñ‡∏¢‡∏î‡∏∂‡∏á‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß‡∏à‡∏≤‡∏Å RESULT (‡πÄ‡∏•‡∏µ‡πà‡∏¢‡∏á‡∏ã‡πâ‡∏≥) ---
    result_vals = ws_result.col_values(1)  # notify_number ‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÅ‡∏£‡∏Å
    if result_vals and result_vals[0] == "notify_number":
        done_set = set(v.strip() for v in result_vals[1:] if v.strip())
    else:
        done_set = set(v.strip() for v in result_vals if v.strip())

    print(f"‚úÖ Already scraped: {len(done_set)}")

    # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡∏î‡∏∂‡∏á
    to_scrape_all = [n for n in notify_all if n not in done_set]

    if not to_scrape_all:
        print("üéâ All records already scraped. Nothing to do.")
        return

    # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô
    to_scrape = to_scrape_all[:MAX_PER_RUN]
    print(f"üßÆ This run will scrape: {len(to_scrape)} records")

    # --- Loop ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ---
    batch_rows = []
    error_rows = []

    for idx, notify in enumerate(to_scrape, start=1):
        regnos = notify.replace("-", "")
        print(f"[{idx}/{len(to_scrape)}] {notify} -> {regnos}")

        detail = call_fda(regnos)

        if detail:
            row = detail_to_row(notify, detail)
            batch_rows.append(row)
        else:
            error_rows.append(
                [notify, regnos, "No data or API error (see logs)"]
            )

        # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô batch ‡∏•‡∏á RESULT ‡∏ó‡∏∏‡∏Å ‡πÜ BATCH_WRITE_SIZE ‡πÅ‡∏ñ‡∏ß
        if len(batch_rows) >= BATCH_WRITE_SIZE:
            ws_result.append_rows(batch_rows, value_input_option="RAW")
            print(f"  üíæ Wrote {len(batch_rows)} rows to RESULT")
            batch_rows = []

        # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô error ‡πÄ‡∏õ‡πá‡∏ô batch
        if len(error_rows) >= BATCH_WRITE_SIZE:
            ws_error.append_rows(error_rows, value_input_option="RAW")
            print(f"  üíæ Wrote {len(error_rows)} rows to ERROR")
            error_rows = []

        # ‡∏Å‡∏±‡∏ô API ‡πÇ‡∏î‡∏ô spam ‡∏à‡∏ô block (‡∏õ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏à‡∏£‡∏¥‡∏á)
        time.sleep(0.2)

    # ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ô‡πÄ‡∏®‡∏© batch ‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠
    if batch_rows:
        ws_result.append_rows(batch_rows, value_input_option="RAW")
        print(f"üíæ Wrote final {len(batch_rows)} rows to RESULT")

    if error_rows:
        ws_error.append_rows(error_rows, value_input_option="RAW")
        print(f"üíæ Wrote final {len(error_rows)} rows to ERROR")

    print("‚úÖ Done this run")


if __name__ == "__main__":
    main()
